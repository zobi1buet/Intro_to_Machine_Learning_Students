{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import sklearn.datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "##Seaborn for fancy plots. \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (8,8)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search, Hyperparameters, and Cross Validation\n",
    "\n",
    "A large part of setting up machine learning models involves repetitive trials, and trial and error tests. We have several tools that can largely automate this trial process, saving us the trouble of making repetitive loops and managing large lists of test values and results. \n",
    "\n",
    "One of the things that we can use this for is to find good values for what we call Hyperparameters - or the values that steer the model creation process. \n",
    "\n",
    "\n",
    "### What the Heck is a Hyperparameter?\n",
    "\n",
    "A hyperparameter is a futuristic term for a simple concept - hyperparameters are the settings that dictate how a machine learning algorithm will behave during training. Hyperparameters are generally the arguments that we provide when creating a model in code. \n",
    "\n",
    "Hyperparameters can be contrasted with regular parameters:\n",
    "<ul>\n",
    "<li> Hyperparameters are defined <b>outside</b> of the training process and control how that process works. To adjust a hyperparameter we need to do it by \"hand\" (more on this later), the algorithm can't figure out the optimal setting during training. The hyperparameters are basically the configuration settings used for the model creation process. \n",
    "<li> Parameters exist <b>inside</b> the training process, and these are adjusted by the algorithm during training. Put differently, parameters are the things that the model needs (in combination with an input) to generate a prediction - in linear regression, the parameters are the slope and intercept.\n",
    "</ul>\n",
    "\n",
    "This means that to get an accurate model we generally have two processes of determining the \"best\" model, one that we handle manually (hyperparameters), and one that is done within the training process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def sklearn_to_df(sklearn_dataset):\n",
    "    df = pd.DataFrame(sklearn_dataset.data, columns=sklearn_dataset.feature_names)\n",
    "    df['target'] = pd.Series(sklearn_dataset.target)\n",
    "    return df\n",
    "\n",
    "df = sklearn_to_df(sklearn.datasets.load_breast_cancer())\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Generate Decision Tree Model</h4>\n",
    "\n",
    "Create a model with the above data and display the resulting decision tree. \n",
    "\n",
    "The random state thing is to make it generate the same results each run, that's not really needed in general, but trees can be very different on each training run, so this will make things a little more stable as we explore. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "0.9300699300699301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0.6205357142857143, 0.9285714285714286, 'x[22] <= 107.2\\ngini = 0.475\\nsamples = 426\\nvalue = [165, 261]'),\n",
       " Text(0.38392857142857145, 0.7857142857142857, 'x[27] <= 0.134\\ngini = 0.121\\nsamples = 263\\nvalue = [17, 246]'),\n",
       " Text(0.5022321428571429, 0.8571428571428572, 'True  '),\n",
       " Text(0.23214285714285715, 0.6428571428571429, 'x[13] <= 48.975\\ngini = 0.033\\nsamples = 241\\nvalue = [4, 237]'),\n",
       " Text(0.14285714285714285, 0.5, 'x[14] <= 0.003\\ngini = 0.017\\nsamples = 238\\nvalue = [2, 236]'),\n",
       " Text(0.07142857142857142, 0.35714285714285715, 'x[1] <= 19.9\\ngini = 0.32\\nsamples = 5\\nvalue = [1, 4]'),\n",
       " Text(0.03571428571428571, 0.21428571428571427, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(0.10714285714285714, 0.21428571428571427, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.21428571428571427, 0.35714285714285715, 'x[21] <= 33.35\\ngini = 0.009\\nsamples = 233\\nvalue = [1, 232]'),\n",
       " Text(0.17857142857142858, 0.21428571428571427, 'gini = 0.0\\nsamples = 222\\nvalue = [0, 222]'),\n",
       " Text(0.25, 0.21428571428571427, 'x[21] <= 33.8\\ngini = 0.165\\nsamples = 11\\nvalue = [1, 10]'),\n",
       " Text(0.21428571428571427, 0.07142857142857142, 'gini = 0.0\\nsamples = 1\\nvalue = [1, 0]'),\n",
       " Text(0.2857142857142857, 0.07142857142857142, 'gini = 0.0\\nsamples = 10\\nvalue = [0, 10]'),\n",
       " Text(0.32142857142857145, 0.5, 'x[19] <= 0.013\\ngini = 0.444\\nsamples = 3\\nvalue = [2, 1]'),\n",
       " Text(0.2857142857142857, 0.35714285714285715, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(0.35714285714285715, 0.35714285714285715, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(0.5357142857142857, 0.6428571428571429, 'x[21] <= 25.89\\ngini = 0.483\\nsamples = 22\\nvalue = [13, 9]'),\n",
       " Text(0.4642857142857143, 0.5, 'x[27] <= 0.172\\ngini = 0.32\\nsamples = 10\\nvalue = [2, 8]'),\n",
       " Text(0.42857142857142855, 0.35714285714285715, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 8]'),\n",
       " Text(0.5, 0.35714285714285715, 'gini = 0.0\\nsamples = 2\\nvalue = [2, 0]'),\n",
       " Text(0.6071428571428571, 0.5, 'x[19] <= 0.003\\ngini = 0.153\\nsamples = 12\\nvalue = [11, 1]'),\n",
       " Text(0.5714285714285714, 0.35714285714285715, 'gini = 0.0\\nsamples = 1\\nvalue = [0, 1]'),\n",
       " Text(0.6428571428571429, 0.35714285714285715, 'gini = 0.0\\nsamples = 11\\nvalue = [11, 0]'),\n",
       " Text(0.8571428571428571, 0.7857142857142857, 'x[7] <= 0.049\\ngini = 0.167\\nsamples = 163\\nvalue = [148, 15]'),\n",
       " Text(0.7388392857142857, 0.8571428571428572, '  False'),\n",
       " Text(0.7857142857142857, 0.6428571428571429, 'x[17] <= 0.01\\ngini = 0.499\\nsamples = 21\\nvalue = [10, 11]'),\n",
       " Text(0.75, 0.5, 'x[1] <= 15.805\\ngini = 0.355\\nsamples = 13\\nvalue = [10, 3]'),\n",
       " Text(0.7142857142857143, 0.35714285714285715, 'gini = 0.0\\nsamples = 3\\nvalue = [0, 3]'),\n",
       " Text(0.7857142857142857, 0.35714285714285715, 'gini = 0.0\\nsamples = 10\\nvalue = [10, 0]'),\n",
       " Text(0.8214285714285714, 0.5, 'gini = 0.0\\nsamples = 8\\nvalue = [0, 8]'),\n",
       " Text(0.9285714285714286, 0.6428571428571429, 'x[21] <= 19.385\\ngini = 0.055\\nsamples = 142\\nvalue = [138, 4]'),\n",
       " Text(0.8928571428571429, 0.5, 'x[6] <= 0.157\\ngini = 0.48\\nsamples = 10\\nvalue = [6, 4]'),\n",
       " Text(0.8571428571428571, 0.35714285714285715, 'gini = 0.0\\nsamples = 4\\nvalue = [0, 4]'),\n",
       " Text(0.9285714285714286, 0.35714285714285715, 'gini = 0.0\\nsamples = 6\\nvalue = [6, 0]'),\n",
       " Text(0.9642857142857143, 0.5, 'gini = 0.0\\nsamples = 132\\nvalue = [132, 0]')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 = pd.get_dummies(df, drop_first=True)\n",
    "y = np.array(df2[\"target\"]).reshape(-1,1)\n",
    "X = np.array(df2.drop(columns={\"target\"}))\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=10)\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(clf.get_depth())\n",
    "print(clf.score(X_test, y_test))\n",
    "plot_tree(clf)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing the Algorithm's Function\n",
    "\n",
    "#### What if we want to limit max depth, or similar?\n",
    "\n",
    "Now, if we wanted to run a trial with different max depths we could just change the number in the argument and repeat. If we wanted to get a little more sophisticated, we could write a loop to try a few and see the results. However, what if we want to change several of these hyperparameters in different trials? Writing a nested loop for each different value we're changing could become pretty cumbersome, and the more clunky it is, the more likely we are to make a mistake. \n",
    "\n",
    "### Hyperparameters and GridSearchCV\n",
    "\n",
    "Luckily, this is a common task, so there are prebuilt ways to do it efficiently. What we are doing here is Hyperparameter Tuning, and the tool we'll use is called GridSearchCV, from sklearn. GridSearchCV is effectively a shortcut to nested loops for each hyperparameter - we provide a list of which variables we'd like to change, and which values we'd like the system to try, and it does the messy work of running a bunch of trials behind the scenes for us. Much easier to use, and less prone to making a mistake. \n",
    "\n",
    "For this trial, we'll change the max depth and also the min_samples_split value - this hyperparameter sets how many values must be in one node before it can be split into 2. The default is 2, and this may sometimes lead to overfitting - we can try a few other options. \n",
    "\n",
    "#### Using Grid Search\n",
    "\n",
    "A grid search object fits into the other pipeline objects that we've used before, in a similar way. We specify:\n",
    "<ul>\n",
    "<li> Which algorithm to train/fit. \n",
    "<li> Which hyperparameters to try, and which values to test. \n",
    "<li> The number of cross validation trials (more on this in a moment)\n",
    "</ul>\n",
    "\n",
    "The grid search object will automatically run the entire process that we are used to in training a model - train/test split of the data, train model, check accuracy - but it will do it for each combination of hyperparameter options that we defined in the lists.\n",
    "\n",
    "For the example below, we specified the maximum depth and the minimum number of items before a node can be split, these are two hyperparameters that control how the model's training process runs. The grid search will do the entire process for each possible combination of those values we listed, check the accuracy of the resulting model, and eventually give us the best one. \n",
    "\n",
    "The grid search process is really useful, we don't need to manually guess and test a bunch of different combination of hyperparameters, we can set the potential options and just let it run. In theory, if we were to set every possible option for every possible hyperparameter we'd have an automated way of finding the absolute most accurate set of HP to use, however that would be pretty impractical in terms of time to run. We want to narrow down the possibilities a bit using both our judgement and the results of the model in initial trials and exploration. For example, in this one we can see that the trail run has many layers and many nodes with very small numbers that are split, so that's a good indication we may want to limit those in our grid search. The exact options and what we 'should' try will differ depending on the algorithm we are using. SK Learn also has some variations on the grid search that aim to make the process faster, they implement things like random trials of hyperparameter values or slicing down the potential HP values to try. We won't spend much time looking at these, the concept is the same as the original grid search just with a bit of variance in how the list of HP values to try; you can test one out pretty easily once comfortable with the grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-1.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=5, min_samples_split=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>DecisionTreeClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;gini&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('splitter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22\">\n",
       "            splitter\n",
       "            <span class=\"param-doc-description\">splitter: {\"best\", \"random\"}, default=\"best\"<br><br>The strategy used to choose the split at each node. Supported<br>strategies are \"best\" to choose the best split and \"random\" to choose<br>the best random split.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;best&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">5</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">3</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: int, float or {\"sqrt\", \"log2\"}, default=None<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at<br>  each split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. note::<br><br>    The search for a split does not stop until at least one<br>    valid partition of the node samples is found, even if it requires to<br>    effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls the randomness of the estimator. The features are always<br>randomly permuted at each split, even if ``splitter`` is set to<br>``\"best\"``. When ``max_features < n_features``, the algorithm will<br>select ``max_features`` at random at each split before finding the best<br>split among them. But the best found split may vary across different<br>runs, even if ``max_features=n_features``. That is the case, if the<br>improvement of the criterion is identical for several splits and one<br>split has to be selected at random. To obtain a deterministic behaviour<br>during fitting, ``random_state`` has to be fixed to an integer.<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=class_weight,-dict%2C%20list%20of%20dict%20or%20%22balanced%22%2C%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: dict, list of dict or \"balanced\", default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If None, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-1');</script></body>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=5, min_samples_split=3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Create a dictionary of HP names and lists of potential values. \n",
    "#The grid search will try all of these options. \n",
    "tree_para = {'min_samples_split':[2,3,4,5,6,7],\n",
    "             'max_depth':[3,4,5,6,7,8]\n",
    "            }\n",
    "\n",
    "clf = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=tree_para, cv=10) #See below for the CV argument\n",
    "clf.fit(X_train, y_train)\n",
    "clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voila!!\n",
    "\n",
    "There is not much of a downside to trying every possible combination of every HP, especially for us with our small datasets. The main drawback is that this can become REALLY computationally expensive with lots of options and large amounts of data. The growth in calculation time grows exponentially the more options are added, so for real world datasets just \"trying everything\" is probably prohibitably slow. \n",
    "\n",
    "There are some ways to cut down on useless trials, some are listed in the sklearn documentation. We'll look at making this better more in the future in a little more depth. For large datasets, taking a sample to experiment on is probably a prudent move. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "The CV argument above stands for cross validation - another way to prevent overfitting and increase overall accuracy. Cross validation is basically a supercharged test-train split. \n",
    "\n",
    "The standard test-train split divides the data 70/30ish, and calculating the accuracy using that reserved 30ish percent. \n",
    "\n",
    "Cross validation makes K splits in the data, and repeats this test-train calculation K times. Each time a different subset is the test set, and the rest of the data is the training set. The overall score is the average of all those K trials. There are other methods in addition to K-fold, such as Leave-One-Out, which leaves only 1 example in the test set, and others that stratify to deal with target imbalance. Using these is pretty similar, we'll touch on them later. \n",
    "\n",
    "Cross validation is a very common step in machine learning. It reduces variance in the results as any random difference in the test-train split is negated by all the other samples. In general, cross validation will give more reliable results due to that reduction in variance - that effect being greater when there are outliers (think if one outlier is tested in a linear regression, that amount of error may be substantial). In testing the accuracy of models previously we'd occasionally see wild variations in the results due to randomness in how the data ended up being split, this cross validation process (largely) neutralizes that issue. \n",
    "\n",
    "We will use a separate cross validation in the future, it is also in sklearn and is pretty straightforward. We commonly use it as part of the grid search as we have here, since both are common this makes it easier and more compact. There are also a few more options that we'll tweak later on, but they are pretty simple. \n",
    "\n",
    "<h3>Why is There Still a Test Set?</h3>\n",
    "\n",
    "The image (from sklearn), and the code below, employ both the test-train split and the cross validation. This is the technically correct way to do it. We want to test on data that the model has never encountered in its training. In this setup, the test set is the same as it always way, and the cross validation creates a bunch of validation splits that help train the data. In practice, if you didn't do this it would rarely have a big impact on the outcome. Examples across the internet will show it both ways, don't worry about it too much, it is a more theoretical concern for our purposes.\n",
    "\n",
    "This does bring up one point that matters when looking to actually use one of these models. All the work we've done so far has been on building and evaluating a predictive model. When that's finished, we'd probably want to use it in production. When this happens we normally want to use all of our data (no test-train split) to create the final model. The idea is that we've already determined that the given algorithm and hyperparameters are good in creating a model, now we want to create a version without that test data withheld so we can benefit from all the data in making the final model. We won't have a real test score for this model, as there is no leftover data to test it on, but we can pretty safely assume that it'll be at least as good as the one we built with a split. \n",
    "\n",
    "![Cross Validation](images/grid_search_cross_validation.png \"Cross Validation\" )\n",
    "\n",
    "<b>From the sklearn documentation:</b>\n",
    "\n",
    "> When evaluating the resulting model it is important to do it on held-out samples that were not seen during the grid search process: it is recommended to split the data into a development set (to be fed to the GridSearchCV instance) and an evaluation set to compute performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Scoring\n",
    "\n",
    "We can use cross validation scoring on its own in place of normal scoring very easily to get a cross-validated version of the training scores, just replace the score function with cross_val_score. The result becomes an array of all the scores. \n",
    "\n",
    "A K value of 5 to 10 is pretty typical. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9122807  0.9122807  0.9122807  0.95614035 0.89380531]\n",
      "0.9173575531749728\n"
     ]
    }
   ],
   "source": [
    "#Cross validation scoring\n",
    "crossV = DecisionTreeClassifier()\n",
    "scores = cross_val_score(crossV, X, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise - Make Your Own Grid\n",
    "\n",
    "Try to make a similar gridsearch with some differnent hyperparamaters. Look on the documentation page in sklearn and try a few options. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.951048951048951\n"
     ]
    }
   ],
   "source": [
    "#EXERCISE\n",
    "#Create a dictionary of HP names and lists of potential values. \n",
    "#The grid search will try all of these options.\n",
    "# \n",
    "exercise_grid = {\n",
    "    \"max_leaf_nodes\": [4, 8, 12, 16],\n",
    "    \"ccp_alpha\": [.0001, .001, .01, .1, 1],\n",
    "    \"criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "ex_clf = GridSearchCV(estimator=DecisionTreeClassifier(), param_grid=exercise_grid, cv=16)\n",
    "ex_clf.fit(X_train, y_train)\n",
    "print(ex_clf.score(X_test, y_test))\n",
    "best_ex = ex_clf.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ccp_alpha': 0.0001,\n",
       " 'class_weight': None,\n",
       " 'criterion': 'entropy',\n",
       " 'max_depth': None,\n",
       " 'max_features': None,\n",
       " 'max_leaf_nodes': 12,\n",
       " 'min_impurity_decrease': 0.0,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'min_weight_fraction_leaf': 0.0,\n",
       " 'monotonic_cst': None,\n",
       " 'random_state': None,\n",
       " 'splitter': 'best'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_ex.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.113e+01 1.662e+01 7.047e+01 3.811e+02 8.151e-02 3.834e-02 1.369e-02\n",
      "  1.370e-02 1.511e-01 6.148e-02 1.415e-01 9.671e-01 9.680e-01 9.704e+00\n",
      "  5.883e-03 6.263e-03 9.398e-03 6.189e-03 2.009e-02 2.377e-03 1.168e+01\n",
      "  2.029e+01 7.435e+01 4.211e+02 1.030e-01 6.219e-02 4.580e-02 4.044e-02\n",
      "  2.383e-01 7.083e-02]]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(X_test[0].reshape(1,-1))\n",
    "print(best_ex.predict(X_test[0].reshape(1,-1))[0] )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search and Cross Validation\n",
    "\n",
    "One note to pay attention to as we start using these tools is that they can easily cause the amount of processing time needed to explode, since each trial is effectively a full end-to-end training process. Taking care to limit the number of options in a grid search, capping the number of cross validation trials, and performing initial work with a sample of the full data can all help prevent the time from running away. There are no strict rules on \"how much stuff to try\", if things take forever to run, start dialing some stuff back. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Models - Random Forest\n",
    "\n",
    "One common improvement made when using trees is to use several of them, or make a forest instead of a tree. More generally, this is our first look at an ensemble model - combining two or more predictive models to make a final prediction. \n",
    "\n",
    "The most simple way to create an ensemble is to use a Random Forest, which generates several trees that make predictions in parallel, then those predictions are combined (for a classification, majority wins) to make the final prediction. The magic behind this is that we are creating several uncorrelated predictions - each tree is generated from a random subset of the data. \n",
    "\n",
    "Random forests employ an ensemble method called Bagging, meaning that we run a bunch of models parallel to each other and get the result by combining the individual results; i.e. all the models are in a bag, and we pull out their combined answer. Another ensemble method is called boosting - using the results of one model's predictions to improve another's; we will look at boosting later on. \n",
    "\n",
    "Random forests will generally deliver more accuracy and less overfitting than a singular tree. More specifically it will tend to reduce the variance in the predictions, as overfitting tends to 'cancel out' (sklearn's words) when many trees are created independently.\n",
    "\n",
    "![Random Forest](images/random_forest.png \"Random Forest\" )\n",
    "\n",
    "Using a Ramdom Forest is pretty easy, we can try one with a grid search, and up the number of HPs that we are tuning. Check the documentation page for a look at the parameters that we could use: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html \n",
    "\n",
    "<b>Note:</b> the n_jobs argument is optional, that tells the system to create that number of threads, and those threads will be run in parallel on different cores of the computer. Modern CPUs have a bunch of cores 4-16 or more, so there's potential for some speedup there. My work Macbook I made this on has 4 (which I think can each double thread, to 8). If you get a weird error, just remove this. This isn't really a need to know, but it may speed some stuff up here and there. If someone were doing this on a powerful server you might have 64 cores, so you'd set that number to be high to ensure that calculations went in parallel on each one. \n",
    "\n",
    "### Bootstrapping\n",
    "\n",
    "One key step that we have when using a random forest is bootstrapping, or making the datasets that each of those models in the ensemble use. Bootstrapping generates random sets of data for each model by selecting data from the full training set. Each dataset is the same size as the original data, but it contains items that were selected randomly, with replacement. I.e. if our dataset is 100 items, to create each dataset while bootstrapping we would randomly pick an item from the full data, put that value in the boostrap set, leave the original in the full dataset (the original data stays at 100 items), and repeat that 100 times. The end result is a bunch of datasets that are very similar to the original, but slightly, and randomly, different. \n",
    "\n",
    "This bootstrapping step generates datasets that help the models be more resistant to overfitting, in simple terms it is harder for a model to overfit if the data it is being fit to is different in each of many (in the case of a forest, often 100) models. While one tree model might be able to overfit to its training data, there are very low odds of all 100 models getting a dataset that allows the same overfitting to happen, so the overfit models will be \"overruled\" when the final vote happens. \n",
    "\n",
    "### Feature Sampling\n",
    "\n",
    "Ensables can also apply the same bootstrapping idea to the feature set - rather than use all the features to train the models, take some randomized subset for each model. This is kind of an odd concept, as we are purposefully removing data, but it can be helpful, mainly in combatting overfitting. We'll examine this idea a bit more when looking at neural networks and their ability to use a \"dropout\" to remove individual features from the training data at random.  \n",
    "\n",
    "### Be Weak to be Strong\n",
    "\n",
    "Ensemble models bring up a concept that we will focus on in more depth when we look at boosting ensembles and neural networks later on, the idea of weak and strong learners. The differentiation between weak and strong predictive models are (this is in the context of classification models):\n",
    "<ul>\n",
    "<li> <b>Strong Learners:</b>\n",
    "    <ul>\n",
    "    <li> Perform much better than random guessing. \n",
    "    <li> Take \"more effort\" to train and run. \n",
    "    <li> Most of the models we look at will fall into this category - logistic regression, SVM, etc...\n",
    "    </ul>\n",
    "<li> <b>Weak Learners:</b>\n",
    "    <ul>\n",
    "    <li> Perform slightly better than random guessing. \n",
    "    <li> Take little time/effort to train or use. \n",
    "    <li> \"Small\" versions of models such as 1 layer trees. \n",
    "    </ul>\n",
    "</ul>\n",
    "\n",
    "This distinction seems kind of odd at first glance, as there doesn't really seem to be much of a reason to ever use or care about a weak learner - why do we want something that does worse? Ensemble models seek to overcome this by assembling multiple weak (or weaker) models together, taking advantage of the speed and non-overfitting of weak models to generate results that are (ideally) better than a standard strong model. The ensembles we will look at now like a random forest normally combine a bunch of slightly \"weaker\" (usually not 1 layer, but normally not a massively large tree) models together to create a better model. When we look at boosted (another ensemble technique) ensembles, we'll spend more time on this. \n",
    "\n",
    "![Weak Learner](images/weak_learn.png \"Weak Learner\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.light {\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: black;\n",
       "  --sklearn-color-background: white;\n",
       "  --sklearn-color-border-box: black;\n",
       "  --sklearn-color-icon: #696969;\n",
       "}\n",
       "\n",
       "#sk-container-id-2.dark {\n",
       "  --sklearn-color-text-on-default-background: white;\n",
       "  --sklearn-color-background: #111;\n",
       "  --sklearn-color-border-box: white;\n",
       "  --sklearn-color-icon: #878787;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-2 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-2 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: center;\n",
       "  justify-content: center;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-2 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-2 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-2 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  border: var(--sklearn-color-fitted-level-0) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-0);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-2 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table {\n",
       "    font-family: monospace;\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table summary::marker {\n",
       "    font-size: 0.7rem;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "    margin-top: 0;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       "/*\n",
       "    `table td`is set in notebook with right text-align.\n",
       "    We need to overwrite it.\n",
       "*/\n",
       ".estimator-table table td.param {\n",
       "    text-align: left;\n",
       "    position: relative;\n",
       "    padding: 0;\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td.value {\n",
       "    color:rgb(255, 94, 0);\n",
       "    background-color: transparent;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left !important;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       "/*\n",
       "    Styles for parameter documentation links\n",
       "    We need styling for visited so jupyter doesn't overwrite it\n",
       "*/\n",
       "a.param-doc-link,\n",
       "a.param-doc-link:link,\n",
       "a.param-doc-link:visited {\n",
       "    text-decoration: underline dashed;\n",
       "    text-underline-offset: .3em;\n",
       "    color: inherit;\n",
       "    display: block;\n",
       "    padding: .5em;\n",
       "}\n",
       "\n",
       "/* \"hack\" to make the entire area of the cell containing the link clickable */\n",
       "a.param-doc-link::before {\n",
       "    position: absolute;\n",
       "    content: \"\";\n",
       "    inset: 0;\n",
       "}\n",
       "\n",
       ".param-doc-description {\n",
       "    display: none;\n",
       "    position: absolute;\n",
       "    z-index: 9999;\n",
       "    left: 0;\n",
       "    padding: .5ex;\n",
       "    margin-left: 1.5em;\n",
       "    color: var(--sklearn-color-text);\n",
       "    box-shadow: .3em .3em .4em #999;\n",
       "    width: max-content;\n",
       "    text-align: left;\n",
       "    max-height: 10em;\n",
       "    overflow-y: auto;\n",
       "\n",
       "    /* unfitted */\n",
       "    background: var(--sklearn-color-unfitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       "/* Fitted state for parameter tooltips */\n",
       ".fitted .param-doc-description {\n",
       "    /* fitted */\n",
       "    background: var(--sklearn-color-fitted-level-0);\n",
       "    border: thin solid var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".param-doc-link:hover .param-doc-description {\n",
       "    display: block;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(criterion=&#x27;entropy&#x27;, max_depth=7, max_samples=0.6,\n",
       "                       min_samples_split=7, n_estimators=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>RandomForestClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html\">?<span>Documentation for RandomForestClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_estimators',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_estimators,-int%2C%20default%3D100\">\n",
       "            n_estimators\n",
       "            <span class=\"param-doc-description\">n_estimators: int, default=100<br><br>The number of trees in the forest.<br><br>.. versionchanged:: 0.22<br>   The default value of ``n_estimators`` changed from 10 to 100<br>   in 0.22.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">20</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('criterion',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22\">\n",
       "            criterion\n",
       "            <span class=\"param-doc-description\">criterion: {\"gini\", \"entropy\", \"log_loss\"}, default=\"gini\"<br><br>The function to measure the quality of a split. Supported criteria are<br>\"gini\" for the Gini impurity and \"log_loss\" and \"entropy\" both for the<br>Shannon information gain, see :ref:`tree_mathematical_formulation`.<br>Note: This parameter is tree-specific.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;entropy&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_depth',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone\">\n",
       "            max_depth\n",
       "            <span class=\"param-doc-description\">max_depth: int, default=None<br><br>The maximum depth of the tree. If None, then nodes are expanded until<br>all leaves are pure or until all leaves contain less than<br>min_samples_split samples.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_split',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2\">\n",
       "            min_samples_split\n",
       "            <span class=\"param-doc-description\">min_samples_split: int or float, default=2<br><br>The minimum number of samples required to split an internal node:<br><br>- If int, then consider `min_samples_split` as the minimum number.<br>- If float, then `min_samples_split` is a fraction and<br>  `ceil(min_samples_split * n_samples)` are the minimum<br>  number of samples for each split.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">7</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_samples_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1\">\n",
       "            min_samples_leaf\n",
       "            <span class=\"param-doc-description\">min_samples_leaf: int or float, default=1<br><br>The minimum number of samples required to be at a leaf node.<br>A split point at any depth will only be considered if it leaves at<br>least ``min_samples_leaf`` training samples in each of the left and<br>right branches.  This may have the effect of smoothing the model,<br>especially in regression.<br><br>- If int, then consider `min_samples_leaf` as the minimum number.<br>- If float, then `min_samples_leaf` is a fraction and<br>  `ceil(min_samples_leaf * n_samples)` are the minimum<br>  number of samples for each node.<br><br>.. versionchanged:: 0.18<br>   Added float values for fractions.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">1</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_weight_fraction_leaf',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0\">\n",
       "            min_weight_fraction_leaf\n",
       "            <span class=\"param-doc-description\">min_weight_fraction_leaf: float, default=0.0<br><br>The minimum weighted fraction of the sum total of weights (of all<br>the input samples) required to be at a leaf node. Samples have<br>equal weight when sample_weight is not provided.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_features',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_features,-%7B%22sqrt%22%2C%20%22log2%22%2C%20None%7D%2C%20int%20or%20float%2C%20default%3D%22sqrt%22\">\n",
       "            max_features\n",
       "            <span class=\"param-doc-description\">max_features: {\"sqrt\", \"log2\", None}, int or float, default=\"sqrt\"<br><br>The number of features to consider when looking for the best split:<br><br>- If int, then consider `max_features` features at each split.<br>- If float, then `max_features` is a fraction and<br>  `max(1, int(max_features * n_features_in_))` features are considered at each<br>  split.<br>- If \"sqrt\", then `max_features=sqrt(n_features)`.<br>- If \"log2\", then `max_features=log2(n_features)`.<br>- If None, then `max_features=n_features`.<br><br>.. versionchanged:: 1.1<br>    The default of `max_features` changed from `\"auto\"` to `\"sqrt\"`.<br><br>Note: the search for a split does not stop until at least one<br>valid partition of the node samples is found, even if it requires to<br>effectively inspect more than ``max_features`` features.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">&#x27;sqrt&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_leaf_nodes',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone\">\n",
       "            max_leaf_nodes\n",
       "            <span class=\"param-doc-description\">max_leaf_nodes: int, default=None<br><br>Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>Best nodes are defined as relative reduction in impurity.<br>If None then unlimited number of leaf nodes.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('min_impurity_decrease',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0\">\n",
       "            min_impurity_decrease\n",
       "            <span class=\"param-doc-description\">min_impurity_decrease: float, default=0.0<br><br>A node will be split if this split induces a decrease of the impurity<br>greater than or equal to this value.<br><br>The weighted impurity decrease equation is the following::<br><br>    N_t / N * (impurity - N_t_R / N_t * right_impurity<br>                        - N_t_L / N_t * left_impurity)<br><br>where ``N`` is the total number of samples, ``N_t`` is the number of<br>samples at the current node, ``N_t_L`` is the number of samples in the<br>left child, and ``N_t_R`` is the number of samples in the right child.<br><br>``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>if ``sample_weight`` is passed.<br><br>.. versionadded:: 0.19</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('bootstrap',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=bootstrap,-bool%2C%20default%3DTrue\">\n",
       "            bootstrap\n",
       "            <span class=\"param-doc-description\">bootstrap: bool, default=True<br><br>Whether bootstrap samples are used when building trees. If False, the<br>whole dataset is used to build each tree.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('oob_score',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=oob_score,-bool%20or%20callable%2C%20default%3DFalse\">\n",
       "            oob_score\n",
       "            <span class=\"param-doc-description\">oob_score: bool or callable, default=False<br><br>Whether to use out-of-bag samples to estimate the generalization score.<br>By default, :func:`~sklearn.metrics.accuracy_score` is used.<br>Provide a callable with signature `metric(y_true, y_pred)` to use a<br>custom metric. Only available if `bootstrap=True`.<br><br>For an illustration of out-of-bag (OOB) error estimation, see the example<br>:ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('n_jobs',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone\">\n",
       "            n_jobs\n",
       "            <span class=\"param-doc-description\">n_jobs: int, default=None<br><br>The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,<br>:meth:`decision_path` and :meth:`apply` are all parallelized over the<br>trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`<br>context. ``-1`` means using all processors. See :term:`Glossary<br><n_jobs>` for more details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone\">\n",
       "            random_state\n",
       "            <span class=\"param-doc-description\">random_state: int, RandomState instance or None, default=None<br><br>Controls both the randomness of the bootstrapping of the samples used<br>when building trees (if ``bootstrap=True``) and the sampling of the<br>features to consider when looking for the best split at each node<br>(if ``max_features < n_features``).<br>See :term:`Glossary <random_state>` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('verbose',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=verbose,-int%2C%20default%3D0\">\n",
       "            verbose\n",
       "            <span class=\"param-doc-description\">verbose: int, default=0<br><br>Controls the verbosity when fitting and predicting.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=warm_start,-bool%2C%20default%3DFalse\">\n",
       "            warm_start\n",
       "            <span class=\"param-doc-description\">warm_start: bool, default=False<br><br>When set to ``True``, reuse the solution of the previous call to fit<br>and add more estimators to the ensemble, otherwise, just fit a whole<br>new forest. See :term:`Glossary <warm_start>` and<br>:ref:`tree_ensemble_warm_start` for details.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('class_weight',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=class_weight,-%7B%22balanced%22%2C%20%22balanced_subsample%22%7D%2C%20dict%20or%20list%20of%20dicts%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone\">\n",
       "            class_weight\n",
       "            <span class=\"param-doc-description\">class_weight: {\"balanced\", \"balanced_subsample\"}, dict or list of dicts,             default=None<br><br>Weights associated with classes in the form ``{class_label: weight}``.<br>If not given, all classes are supposed to have weight one. For<br>multi-output problems, a list of dicts can be provided in the same<br>order as the columns of y.<br><br>Note that for multioutput (including multilabel) weights should be<br>defined for each class of every column in its own dict. For example,<br>for four-class multilabel classification weights should be<br>[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>[{1:1}, {2:5}, {3:1}, {4:1}].<br><br>The \"balanced\" mode uses the values of y to automatically adjust<br>weights inversely proportional to class frequencies in the input data<br>as ``n_samples / (n_classes * np.bincount(y))``<br><br>The \"balanced_subsample\" mode is the same as \"balanced\" except that<br>weights are computed based on the bootstrap sample for every tree<br>grown.<br><br>For multi-output, the weights of each column of y will be multiplied.<br><br>Note that these weights will be multiplied with sample_weight (passed<br>through the fit method) if sample_weight is specified.</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('ccp_alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0\">\n",
       "            ccp_alpha\n",
       "            <span class=\"param-doc-description\">ccp_alpha: non-negative float, default=0.0<br><br>Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>subtree with the largest cost complexity that is smaller than<br>``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>:ref:`minimal_cost_complexity_pruning` for details. See<br>:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>for an example of such pruning.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.0</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_samples',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_samples,-int%20or%20float%2C%20default%3DNone\">\n",
       "            max_samples\n",
       "            <span class=\"param-doc-description\">max_samples: int or float, default=None<br><br>If bootstrap is True, the number of samples to draw from X<br>to train each base estimator.<br><br>- If None (default), then draw `X.shape[0]` samples.<br>- If int, then draw `max_samples` samples.<br>- If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,<br>  `max_samples` should be in the interval `(0.0, 1.0]`.<br><br>.. versionadded:: 0.22</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">0.6</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('monotonic_cst',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">\n",
       "        <a class=\"param-doc-link\"\n",
       "            rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone\">\n",
       "            monotonic_cst\n",
       "            <span class=\"param-doc-description\">monotonic_cst: array-like of int of shape (n_features), default=None<br><br>Indicates the monotonicity constraint to enforce on each feature.<br>  - 1: monotonic increase<br>  - 0: no constraint<br>  - -1: monotonic decrease<br><br>If monotonic_cst is None, no constraints are applied.<br><br>Monotonicity constraints are not supported for:<br>  - multiclass classifications (i.e. when `n_classes > 2`),<br>  - multioutput classifications (i.e. when `n_outputs_ > 1`),<br>  - classifications trained on data with missing values.<br><br>The constraints hold over the probability of the positive class.<br><br>Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br><br>.. versionadded:: 1.4</span>\n",
       "        </a>\n",
       "    </td>\n",
       "            <td class=\"value\">None</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.copy-paste-icon').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling\n",
       "        .textContent.trim().split(' ')[0];\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "\n",
       "\n",
       "/**\n",
       " * Adapted from Skrub\n",
       " * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789\n",
       " * @returns \"light\" or \"dark\"\n",
       " */\n",
       "function detectTheme(element) {\n",
       "    const body = document.querySelector('body');\n",
       "\n",
       "    // Check VSCode theme\n",
       "    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');\n",
       "    const themeNameAttr = body.getAttribute('data-vscode-theme-name');\n",
       "\n",
       "    if (themeKindAttr && themeNameAttr) {\n",
       "        const themeKind = themeKindAttr.toLowerCase();\n",
       "        const themeName = themeNameAttr.toLowerCase();\n",
       "\n",
       "        if (themeKind.includes(\"dark\") || themeName.includes(\"dark\")) {\n",
       "            return \"dark\";\n",
       "        }\n",
       "        if (themeKind.includes(\"light\") || themeName.includes(\"light\")) {\n",
       "            return \"light\";\n",
       "        }\n",
       "    }\n",
       "\n",
       "    // Check Jupyter theme\n",
       "    if (body.getAttribute('data-jp-theme-light') === 'false') {\n",
       "        return 'dark';\n",
       "    } else if (body.getAttribute('data-jp-theme-light') === 'true') {\n",
       "        return 'light';\n",
       "    }\n",
       "\n",
       "    // Guess based on a parent element's color\n",
       "    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');\n",
       "    const match = color.match(/^rgb\\s*\\(\\s*(\\d+)\\s*,\\s*(\\d+)\\s*,\\s*(\\d+)\\s*\\)\\s*$/i);\n",
       "    if (match) {\n",
       "        const [r, g, b] = [\n",
       "            parseFloat(match[1]),\n",
       "            parseFloat(match[2]),\n",
       "            parseFloat(match[3])\n",
       "        ];\n",
       "\n",
       "        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness\n",
       "        const luma = 0.299 * r + 0.587 * g + 0.114 * b;\n",
       "\n",
       "        if (luma > 180) {\n",
       "            // If the text is very bright we have a dark theme\n",
       "            return 'dark';\n",
       "        }\n",
       "        if (luma < 75) {\n",
       "            // If the text is very dark we have a light theme\n",
       "            return 'light';\n",
       "        }\n",
       "        // Otherwise fall back to the next heuristic.\n",
       "    }\n",
       "\n",
       "    // Fallback to system preference\n",
       "    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';\n",
       "}\n",
       "\n",
       "\n",
       "function forceTheme(elementId) {\n",
       "    const estimatorElement = document.querySelector(`#${elementId}`);\n",
       "    if (estimatorElement === null) {\n",
       "        console.error(`Element with id ${elementId} not found.`);\n",
       "    } else {\n",
       "        const theme = detectTheme(estimatorElement);\n",
       "        estimatorElement.classList.add(theme);\n",
       "    }\n",
       "}\n",
       "\n",
       "forceTheme('sk-container-id-2');</script></body>"
      ],
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=7, max_samples=0.6,\n",
       "                       min_samples_split=7, n_estimators=20)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_para = {'min_samples_split':[3,4,5,6,7],\n",
    "            'max_depth':[3,4,5,6,7,8],\n",
    "            'n_estimators':[20,50,80],\n",
    "            'criterion':[\"gini\",\"entropy\"],\n",
    "            'max_samples':[.4, .5, .6, .7]}\n",
    "\n",
    "#clf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=rf_para, cv=10)\n",
    "# If you get some weird error, uncomment above, and comment the line below. See the note above for more. \n",
    " \n",
    "clf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=rf_para, cv=10, n_jobs=4) \n",
    "clf.fit(X_train, y_train.ravel())\n",
    "clf.best_estimator_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline with GridSearchCV\n",
    "\n",
    "We can also use this with a pipeline, the main changes are:\n",
    "<ul>\n",
    "<li>The estimator in the grid search becomes the pipeline.\n",
    "<li>The paramaters in the param_grid need to be named \"stepName__variable\". See the example below.\n",
    "</ul>\n",
    "\n",
    "This can be extended pretty much indefinitely, we can have a pipeline as part of a column transformer, as part of another pipeline, etc... all plugged into the Grid Search. As long as calling .fit() and/or .transform() on whatever we put into the grid search is valid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.965034965034965\n",
      "Pipeline(steps=[('scaler', StandardScaler()),\n",
      "                ('forest', RandomForestClassifier(max_depth=9, n_jobs=-1))])\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "scaler = StandardScaler()\n",
    "estimator = RandomForestClassifier(n_jobs=-1)\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), (\"forest\", estimator)])\n",
    "\n",
    "params = {'forest__max_depth':[5,6,7,8,9],\n",
    "          \"scaler__with_mean\":[True, False],\n",
    "}\n",
    " \n",
    "clf = GridSearchCV(pipe, param_grid=params, cv=5, n_jobs=-1) \n",
    "clf.fit(X_train, y_train.ravel())\n",
    "best = clf.best_estimator_\n",
    "print(best.score(X_test, y_test))\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-Tree Bagging\n",
    "\n",
    "In general the BaggingClassifier in sklearn can apply the same concept to other classification methods, and the BaggingRegressor can do the same for regression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.951048951048951"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "bag = BaggingClassifier(estimator=LogisticRegression(max_iter=10000),\n",
    "                        n_estimators=10, random_state=0).fit(X_train, y_train.ravel())\n",
    "bag.score(X_test, y_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - Predict the Target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0       0  \n",
       "1       0  \n",
       "2       0  \n",
       "3       0  \n",
       "4       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ = sklearn_to_df(sklearn.datasets.load_iris())\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "pipe = Pipeline(steps=[(\"scaler\", scaler), \n",
    "                       (\"forest\", RandomForestClassifier(n_estimators=100, n_jobs=-1))])\n",
    "\n",
    "#Data\n",
    "X = np.array(df_.drop(columns={\"target\"}))\n",
    "y = np.array(df_[\"target\"]).reshape(-1,1)\n",
    "\n",
    "#Grid\n",
    "params = {'forest__max_depth':[5,6,7,8,9],\n",
    "            'forest__max_features':[2,3,4]}\n",
    "\n",
    "#Grid search\n",
    "clf2 = GridSearchCV(pipe, param_grid=params, cv=5, n_jobs=-1)\n",
    "clf2.fit(X, y.ravel())\n",
    "best = clf2.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search, But Don't\n",
    "\n",
    "The grid search concept is something that we use all the time in learning about machine learning, but is something that we use much less often in reality. The idea stays the same, but the details of how a grid search works limits its practicality in real-world situation, especially those involving large amounts of data. The basic problem with a grid search is that it requires that we list things to try for each hyperparameter and try each combination. This can result in a search space that is huge, and with non-trivial problems that can mean our grid search needs to test a massive number of trials before determining a winner. \n",
    "\n",
    "In real world applications we want to do the same thing as a grid search, but more efficiently, so we have some grid search variants that make the process of searching through the potential options that a grid search would provide more efficient. One example is the Bayesian search, which uses some smarts to decide which HP values to try more intelligently. Another is a random search, which will randomly test different HP options in a similar way. \n",
    "\n",
    "These variants of a grid search are conceptually the same - we want to try different hyperparameter options to see which performs the best - they just use different methods for selecting which hyperparameter values to try. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_mar_2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
